{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Projeto - Analisando Dados do Uber com Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Original: https://github.com/fivethirtyeight/uber-tlc-foil-response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados original contém dados de mais de 4,5 milhões de captações Uber na cidade de Nova York de abril a setembro de 2014 e 14,3 milhões de captações Uber de janeiro a junho de 2015. Dados em nível de viagem sobre 10 outras empresas de veículos de aluguel (FHV) bem como dados agregados para 329 empresas de FHV, também estão incluídos. Todos os arquivos foram recebidos em 3 de agosto, 15 de setembro e 22 de setembro de 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A análise realizada nesse notebook será feita em um conjunto de dados reduzido para demonstração e aprimoramento dos conhecimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Quantos são e quais são as bases de carros do Uber (onde os carros ficam esperando passageiros)?\n",
    "\n",
    "2- Qual o total de veículos que passaram pela base B02617?\n",
    "\n",
    "3- Qual o total de corridas por base? Apresente de forma decrescente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Etapa 1. Carregando os dados utilizando Pandas e realizando uma análise dos dados existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto\n",
    "uber_dataset = read_csv(\"/data/uber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o tipo do objeto\n",
    "type(uber_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_number</th>\n",
       "      <th>date</th>\n",
       "      <th>active_vehicles</th>\n",
       "      <th>trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02512</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>190</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B02765</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>225</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B02764</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>3427</td>\n",
       "      <td>29421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B02682</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>945</td>\n",
       "      <td>7679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B02617</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>1228</td>\n",
       "      <td>9537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B02598</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>870</td>\n",
       "      <td>6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B02598</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>785</td>\n",
       "      <td>4768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B02617</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>1137</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B02512</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>175</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B02682</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>890</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B02765</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>196</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B02764</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>3147</td>\n",
       "      <td>19974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B02765</td>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>201</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B02617</td>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>1188</td>\n",
       "      <td>10664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B02598</td>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>818</td>\n",
       "      <td>7432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dispatching_base_number      date  active_vehicles  trips\n",
       "0                   B02512  1/1/2015              190   1132\n",
       "1                   B02765  1/1/2015              225   1765\n",
       "2                   B02764  1/1/2015             3427  29421\n",
       "3                   B02682  1/1/2015              945   7679\n",
       "4                   B02617  1/1/2015             1228   9537\n",
       "5                   B02598  1/1/2015              870   6903\n",
       "6                   B02598  1/2/2015              785   4768\n",
       "7                   B02617  1/2/2015             1137   7065\n",
       "8                   B02512  1/2/2015              175    875\n",
       "9                   B02682  1/2/2015              890   5506\n",
       "10                  B02765  1/2/2015              196   1001\n",
       "11                  B02764  1/2/2015             3147  19974\n",
       "12                  B02765  1/3/2015              201   1526\n",
       "13                  B02617  1/3/2015             1188  10664\n",
       "14                  B02598  1/3/2015              818   7432"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_dataset.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Etapa 2: Transformando o dataframe do Pandas em dataframe do Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_dataset_spk = sqlContext.createDataFrame(uber_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uber_dataset_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extra: Transformando um Dataframe Pandas e Dataframe Spark em RDD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando um dataframe do pandas em RDD com a função parallelize do Spark Context\n",
    "df_pandas_rdd = sc.parallelize(uber_dataset)\n",
    "type(df_pandas_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando um dataframe do Spark em RDD através da Operação RDD.\n",
    "df_spark_rdd = uber_dataset_spk.rdd\n",
    "type(df_spark_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Etapa 1 e 2 Extra: Realizando a mesma importação direta com o Spark resultando em um RDD\n",
    "###### Com 1 linha de código realizamos a mesma importação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberRDD = sc.textFile(\"~/data/uber.csv\")\n",
    "type(uberRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_number,date,active_vehicles,trips',\n",
       " 'B02512,1/1/2015,190,1132',\n",
       " 'B02765,1/1/2015,225,1765',\n",
       " 'B02764,1/1/2015,3427,29421',\n",
       " 'B02682,1/1/2015,945,7679',\n",
       " 'B02617,1/1/2015,1228,9537',\n",
       " 'B02598,1/1/2015,870,6903',\n",
       " 'B02598,1/2/2015,785,4768',\n",
       " 'B02617,1/2/2015,1137,7065',\n",
       " 'B02512,1/2/2015,175,875',\n",
       " 'B02682,1/2/2015,890,5506',\n",
       " 'B02765,1/2/2015,196,1001',\n",
       " 'B02764,1/2/2015,3147,19974',\n",
       " 'B02765,1/3/2015,201,1526',\n",
       " 'B02617,1/3/2015,1188,10664']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberRDD.take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B02512,1/1/2015,190,1132',\n",
       " 'B02765,1/1/2015,225,1765',\n",
       " 'B02764,1/1/2015,3427,29421']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo o Header do RDD para facilitar durante a manipulação dos dados\n",
    "uberRDD_header = uberRDD.first()\n",
    "uberRDD_no_header = uberRDD.filter(lambda x : x != uberRDD_header)\n",
    "uberRDD_no_header.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B02512', '1/1/2015', '190', '1132'],\n",
       " ['B02765', '1/1/2015', '225', '1765'],\n",
       " ['B02764', '1/1/2015', '3427', '29421'],\n",
       " ['B02682', '1/1/2015', '945', '7679'],\n",
       " ['B02617', '1/1/2015', '1228', '9537'],\n",
       " ['B02598', '1/1/2015', '870', '6903'],\n",
       " ['B02598', '1/2/2015', '785', '4768'],\n",
       " ['B02617', '1/2/2015', '1137', '7065'],\n",
       " ['B02512', '1/2/2015', '175', '875'],\n",
       " ['B02682', '1/2/2015', '890', '5506']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizando o split do arquivo RDD a cada vez que encontrar o caracter ',' facilitando assim análises futuras\n",
    "# A transformação executada através da operação map, irá resultar em um pipelineRDD.\n",
    "uberRDD_splitted = uberRDD_no_header.map(lambda line: line.split(\",\"))\n",
    "uberRDD_splitted.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uberRDD_splitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1- Quantos são e quais são as bases de carros do Uber (onde os carros ficam esperando passageiros)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de bases de carros distintos da Uber\n",
    "uberRDD_splitted.map(lambda x: x[0]).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B02765', 'B02682', 'B02598', 'B02512', 'B02764', 'B02617']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nome das bases da uber\n",
    "uberRDD_splitted.map(lambda x: x[0]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2- Qual o total de veículos que passaram pela base B02617?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberRDD_splitted.filter(lambda x: 'B02617' in x[0]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3- Qual o total de corridas por base? Apresente de forma decrescente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B02764', 1914449),\n",
       " ('B02617', 725025),\n",
       " ('B02682', 662509),\n",
       " ('B02598', 540791),\n",
       " ('B02765', 193670),\n",
       " ('B02512', 93786)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberRDD_splitted.map(lambda x: (x[0],int(x[3]))).reduceByKey(lambda acc, n: acc + n).sortBy(lambda a: -a[1]).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
